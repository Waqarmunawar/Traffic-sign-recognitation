{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Data from CSV file\n",
    "data = pd.read_csv('data.csv')\n",
    "X = data.iloc[:, :-1].values #Storing feature\n",
    "y = data.iloc[:, -1].values # storing label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding on output\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Normlization\n",
    "X = preprocessing.normalize(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 3 2 0 4 4 3 3 0 4 0 4 3 3 1 2 0 2 0 3 4 2 0 3 3 1 1 4 1 0 1 0 1 0 1 1\n",
      " 0 4 2]\n"
     ]
    }
   ],
   "source": [
    "#80 % traning data 20% testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0, 4.0], [5.0, 6.0], [7.0, 8.0], [1.0, 2.0]]\n"
     ]
    }
   ],
   "source": [
    "# weights intilization for input layer\n",
    "weights_for_input_layer=[]\n",
    "bias1=0.1\n",
    "bias2=0.4\n",
    "for i in range(4):\n",
    "    w1 = float(input(\"Enter weights of w1 : \"))\n",
    "    w2 = float(input(\"Enter weights of w2 : \"))\n",
    "    a = [w1,w2]\n",
    "    weights_for_input_layer.append(a)\n",
    "print(weights_for_input_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 2.0, 3.0, 4.0, 5.0], [6.0, 7.0, 8.0, 9.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "# weights intilization for hidden layer\n",
    "array_for_hidden_weights=[]\n",
    "bias_output_nuron=[0.4,0.2,-0.3,0.6,-0.1]\n",
    "for i in range(2):\n",
    "    h1 = float(input(\"Enter weight of h1 : \"))\n",
    "    h2 = float(input(\"Enter weight of h2 : \"))\n",
    "    h3 = float(input(\"Enter weight of h3 : \"))\n",
    "    h4 = float(input(\"Enter weight of h4 : \"))\n",
    "    h5 = float(input(\"Enter weight of h5 : \"))\n",
    "    b = [h1,h2,h3,h4,h5]\n",
    "    array_for_hidden_weights.append(b)\n",
    "print(array_for_hidden_weights)\n",
    "count=0\n",
    "output_array=[]\n",
    "count2=0\n",
    "j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\smester 6\\ML\\ML Project\\ML Project.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/smester%206/ML/ML%20Project/ML%20Project.ipynb#ch0000007?line=3'>4</a>\u001b[0m m1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(X_train[i][\u001b[39m0\u001b[39m],weights_for_input_layer[count][\u001b[39m0\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/smester%206/ML/ML%20Project/ML%20Project.ipynb#ch0000007?line=4'>5</a>\u001b[0m count\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/smester%206/ML/ML%20Project/ML%20Project.ipynb#ch0000007?line=5'>6</a>\u001b[0m m2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(X_train[i][\u001b[39m1\u001b[39m],weights_for_input_layer[count][\u001b[39m0\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/smester%206/ML/ML%20Project/ML%20Project.ipynb#ch0000007?line=6'>7</a>\u001b[0m count\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/smester%206/ML/ML%20Project/ML%20Project.ipynb#ch0000007?line=7'>8</a>\u001b[0m m3 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(X_train[i][\u001b[39m2\u001b[39m],weights_for_input_layer[count][\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# calculation from input layer to hidden layer\n",
    "hidden_layer = []\n",
    "for i in range(len(X_train)):\n",
    "    m1 = np.dot(X_train[i][0],weights_for_input_layer[count][0])\n",
    "    count+=1\n",
    "    m2 = np.dot(X_train[i][1],weights_for_input_layer[count][0])\n",
    "    count+=1\n",
    "    m3 = np.dot(X_train[i][2],weights_for_input_layer[count][0])\n",
    "    count+=1\n",
    "    m4 = np.dot(X_train[i][3],weights_for_input_layer[count][0])\n",
    "    r1=m1+m2+m3+m4+bias1 #adding bias\n",
    "    sigmoid = 1/(1+np.exp(-r1))\n",
    "    h1=sigmoid\n",
    "    print(r1)\n",
    "    m1 = np.dot(X_train[i][0],weights_for_input_layer[count2][1])\n",
    "    count2+=1\n",
    "    m2 = np.dot(X_train[i][1],weights_for_input_layer[count2][1])\n",
    "    count2+=1\n",
    "    m3 = np.dot(X_train[i][2],weights_for_input_layer[count2][1])\n",
    "    count2+=1\n",
    "    m4 = np.dot(X_train[i][3],weights_for_input_layer[count2][1])\n",
    "    r2=m1+m2+m3+m4+bias2#adding bias\n",
    "    print(r2)\n",
    "    sigmoid = 1/(1+np.exp(-r2))\n",
    "    #storing output from input layer to input into hidden layer\n",
    "    h2=sigmoid\n",
    "    num_of_hidden_layer = [h1,h2]\n",
    "    hidden_layer.append(num_of_hidden_layer)\n",
    "    print(hidden_layer)\n",
    "    for k in range(5):\n",
    "        o1 = np.dot(hidden_layer[0][0],array_for_hidden_weights[0][k])\n",
    "        o2 = np.dot(hidden_layer[0][1],array_for_hidden_weights[1][k])\n",
    "        # print(o1)\n",
    "        # print(o2)\n",
    "        # print(\"\\n\")\n",
    "        outpu1 = o1+o2+bias_output_nuron[k] #adding bias value in outputlayer\n",
    "        sigmoid2=1/(1+np.exp(-outpu1))\n",
    "        output_array.append(sigmoid2)\n",
    "\n",
    "\n",
    "    #storing output from hidden layer to input into output layer\n",
    "print(output_array)\n",
    "y_desire=1\n",
    "y_dash=max(output_array)\n",
    "print(y_dash)\n",
    "c = -1*(y_desire*np.log(y_dash)+(1-y_desire)*np.log(1-y_dash))\n",
    "print(c)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing_tools.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "6cce72f708ad16bfeeb4e76d5afef2a701af35474db85138ca31644528ecf639"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
